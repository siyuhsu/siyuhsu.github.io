---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Siyu Xu is a final-year M.Phil student at The University of Sydney, supervised by A/Prof.  <a href="http://changxu.xyz/">Chang Xu</a>. His research focuses on large multimodal models (LMMs), particularly Vision-Language-Action (VLA) models. His goal is to develop efficient and general-purpose robotic systems capable of understanding and interacting with the world through vision, language, and actions, enabling them to seamlessly assist humans in various real-world tasks and everyday life.


# üî• News
- *2025.01*: &nbsp;üéâüéâ One paper is accepted to **NAACL 2025 Findings**.

# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Arxiv</div><img src='images/vla-cache.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[VLA-Cache: Towards Efficient Vision-Language-Action Model via Adaptive Token Caching in Robotic Manipulation](https://arxiv.org/abs/2502.02175)

**Siyu Xu**, Yunke Wang, Chenghao Xia, Dihao Zhu, Tao Huang, Chang Xu

[Under review]
[[Project]](https://vla-cache.github.io/)
[[Code]](https://github.com/siyuhsu/vla-cache)

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NAACL 2025</div><img src='images/collage_prompt.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[CollagePrompt: A Benchmark for Budget-Friendly Visual Recognition with GPT-4V](https://arxiv.org/abs/2403.11468)

**Siyu Xu**, Yunke Wang, Daochang Liu, Bo Du, Chang Xu

[[Project]](https://collageprompting.github.io/)
[[Code]](https://github.com/siyuhsu/CollagePrompt)

*Conference of the Nations of the Americas Chapter of the ACL (NAACL), 2025*

</div>
</div>



# üéñ Honors and Awards
- *2022.05* Second Class Prize - ASC22 Student Supercomputer Challenge, Asia Supercomputer Community
- *2020.10* First Place Award - Pre-training for Video Captioning Challenge, ACM International Conference on Multimedia
- *2020.10* 7th Place - Artificial Intelligence Competition for Video Generation Challenge, ZHEJIANG LAB
- *2020.05* 9th Place - International Audio and Video Algorithm Optimization Competition, Mongo Media

# üßë‚Äçüè´ Teaching
- *2024 S1*, Tutor of COMP5329, Deep Learning, USYD
- *2023 S2*, Tutor of COMP5328, Advanced Machine Learning, USYD

# üìñ Educations
- *2023.07 - 2025.06*, M.Phil in Computer Vision, University of Sydney
- *2022.08 - 2023.06*, Master of Information Technology, University of Sydney

# üíª Internships
- *2021.03 - 2021.07*, [Matrixtime Robotics](https://www.matrixtime.com/), China.